# Automatisation ETL - Guide d'Utilisation

## ğŸ¯ Objectif
Script d'automatisation complÃ¨te du chargement ETL post-transformations avec:
- Gestion d'erreurs avancÃ©e
- Logs dÃ©taillÃ©s
- Retry automatique
- Checkpoints
- Validation qualitÃ©
- Snapshots avant chargement

## ğŸš€ Utilisation

### ExÃ©cution simple (recommandÃ©e)
```powershell
cd TRANSFORM/R2W
python autoload_etl.py
```

### Avec environnement virtuel
```powershell
cd TRANSFORM/R2W
.venv\Scripts\Activate.ps1
python autoload_etl.py
```

## ğŸ“‹ Ce que fait le script

### Phase 0: VÃ©rifications prÃ©-chargement
- âœ… Test connexion PostgreSQL
- ğŸ’¾ Snapshot des comptages actuels (pour rollback)

### Phase 1: Chargement Dimensions
- ExÃ©cute `load_dimensions.py`
- Charge 8 dimensions (Agent, Team, Competition, Season, Injury Type, Transfer Type, Player, Date)
- Retry automatique en cas d'Ã©chec (max 3 tentatives)

### Phase 2: Chargement Faits
- ExÃ©cute `load_facts.py`
- Charge 7 tables de faits (Performance, Market Value, Transfer, Injury, National Performance, Teammate Relationship, Player Season Summary)
- Retry automatique

### Phase 3: Validation QualitÃ©
- VÃ©rification comptages non-nuls
- Test intÃ©gritÃ© rÃ©fÃ©rentielle (FK valides)
- DÃ©tection enregistrements orphelins

### Phase 4: VÃ©rification Finale
- ExÃ©cute `verify_warehouse.py`
- Rapport complet sur toutes les tables

## ğŸ“Š Logs & Outputs

### Logs dÃ©taillÃ©s
- Fichier: `logs/etl_auto_YYYYMMDD_HHMMSS.log`
- Console + fichier simultanÃ©ment
- Timestamps sur toutes les opÃ©rations

### Checkpoint
- Fichier: `etl_checkpoint.json`
- Sauvegarde progression Ã  chaque Ã©tape
- Permet reprise en cas d'interruption

### Snapshot
- Fichier: `logs/snapshot_YYYYMMDD_HHMMSS.json`
- Comptages tables avant chargement
- Utilisable pour rollback manuel

## âš™ï¸ Configuration

Ã‰ditez les variables dans `autoload_etl.py`:

```python
ETL_CONFIG = {
    'max_retries': 3,              # Nombre de tentatives par script
    'retry_delay': 5,              # DÃ©lai entre tentatives (sec)
    'enable_rollback': True,       # CrÃ©er snapshot avant chargement
    'enable_notifications': False, # Notifications email/Slack (TODO)
    'parallel_load': False,        # Chargement parallÃ¨le (future)
    'checkpoint_file': 'etl_checkpoint.json'
}
```

## ğŸ”„ Reprise aprÃ¨s Ã©chec

Si le script Ã©choue Ã  une Ã©tape:

1. **VÃ©rifier les logs**
   ```powershell
   Get-Content logs\etl_auto_YYYYMMDD_HHMMSS.log -Tail 50
   ```

2. **Consulter checkpoint**
   ```powershell
   Get-Content etl_checkpoint.json
   ```

3. **Corriger le problÃ¨me** (connexion DB, donnÃ©es, etc.)

4. **Relancer le script**
   ```powershell
   python autoload_etl.py
   ```

## ğŸ“ˆ Exemple de sortie

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    AUTOMATISATION ETL POST-TRANSFORMATIONS                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â° DÃ©but: 2025-11-18 14:30:00

================================================================================
PHASE 0: VÃ‰RIFICATIONS PRÃ‰-CHARGEMENT
================================================================================
ğŸ” VÃ©rification de la connexion Ã  la base de donnÃ©es...
âœ… Connexion Ã©tablie: PostgreSQL 15.3
ğŸ’¾ CrÃ©ation du snapshot de sauvegarde...
âœ… Snapshot sauvegardÃ©: logs/snapshot_20251118_143000.json

================================================================================
PHASE 1: CHARGEMENT DES DIMENSIONS (8 tables)
================================================================================
â–¶ï¸  EXÃ‰CUTION: Dimensions (Agent, Team, Competition, Season, Injury, Player)
ğŸ“„ Script: load_dimensions.py
...
âœ… Dimensions (Agent, Team, Competition, Season, Injury, Player) - SUCCÃˆS

================================================================================
PHASE 2: CHARGEMENT DES FAITS (7 tables)
================================================================================
â–¶ï¸  EXÃ‰CUTION: Faits (Performance, Market Value, Transfer, Injury, etc.)
ğŸ“„ Script: load_facts.py
...
âœ… Faits (Performance, Market Value, Transfer, Injury, etc.) - SUCCÃˆS

================================================================================
PHASE 3: VALIDATION QUALITÃ‰
================================================================================
ğŸ” Validation de la qualitÃ© des donnÃ©es...
  âœ… dim_player: 40,547 lignes
  âœ… fact_player_performance: 139,444 lignes
  âœ… fact_market_value: 425,302 lignes
  âœ… IntÃ©gritÃ© rÃ©fÃ©rentielle: OK

================================================================================
PHASE 4: VÃ‰RIFICATION FINALE
================================================================================
â–¶ï¸  EXÃ‰CUTION: VÃ©rification complÃ¨te du Data Warehouse
ğŸ“„ Script: verify_warehouse.py
...
âœ… VÃ©rification complÃ¨te du Data Warehouse - SUCCÃˆS

================================================================================
RÃ‰SUMÃ‰ DE L'EXÃ‰CUTION ETL
================================================================================
  âœ… Dimensions                      SUCCÃˆS
  âœ… Faits                           SUCCÃˆS
  âœ… Validation QualitÃ©              SUCCÃˆS
  âœ… VÃ©rification                    SUCCÃˆS

â±ï¸  DurÃ©e totale: 0:08:32
ğŸ“… Fin: 2025-11-18 14:38:32
ğŸ“„ Log dÃ©taillÃ©: logs/etl_auto_20251118_143000.log

ğŸ“Š VOLUMÃ‰TRIE FINALE:
  dim_agent                          :        3,397 lignes
  dim_competition                    :          107 lignes
  dim_date                           :        9,085 lignes
  dim_injury_type                    :            4 lignes
  dim_player                         :       40,547 lignes
  dim_season                         :           56 lignes
  dim_team                           :        1,304 lignes
  dim_transfer_type                  :            6 lignes
  fact_injury                        :       77,543 lignes
  fact_market_value                  :      425,302 lignes
  fact_national_performance          :       62,144 lignes
  fact_player_performance            :      139,444 lignes
  fact_player_season_summary         :      126,869 lignes
  fact_teammate_relationship         :      437,371 lignes
  fact_transfer                      :      277,676 lignes

================================================================================
ğŸ‰ ETL AUTOMATISÃ‰ COMPLÃ‰TÃ‰ AVEC SUCCÃˆS!
================================================================================
```

## ğŸ› ï¸ DÃ©pannage

### Erreur: "Connexion DB impossible"
```powershell
# VÃ©rifier Docker
docker ps | findstr football_data_postgres

# RedÃ©marrer conteneur si nÃ©cessaire
cd TRANSFORM/DATABASE
docker-compose up -d
```

### Erreur: "Module not found"
```powershell
# Installer dÃ©pendances
pip install psycopg2-binary pandas python-dotenv tqdm tabulate
```

### Erreur: Fichier .env manquant
```powershell
# VÃ©rifier prÃ©sence
Test-Path TRANSFORM/DATABASE/.env

# Si absent, crÃ©er avec:
# DB_HOST=localhost
# DB_PORT=5432
# DB_NAME=football_data_sa
# DB_USER=football_admin
# DB_PASSWORD=football_pass_2025
```

## ğŸ“… Planification automatique (Windows)

### TÃ¢che planifiÃ©e quotidienne
```powershell
# CrÃ©er script batch: run_etl_scheduled.bat
@echo off
cd C:\Users\Fares\Videos\SYSDECPRO\TRANSFORM\R2W
C:\Users\Fares\AppData\Local\Programs\Python\Python311\python.exe autoload_etl.py
pause

# CrÃ©er tÃ¢che planifiÃ©e (Task Scheduler)
schtasks /create /tn "ETL_Football_Daily" /tr "C:\path\to\run_etl_scheduled.bat" /sc daily /st 02:00
```

## ğŸ”® Ã‰volutions futures

- [ ] Notifications email/Slack en cas d'Ã©chec
- [ ] Chargement parallÃ¨le des faits indÃ©pendants
- [ ] Rollback automatique en cas d'Ã©chec critique
- [ ] Dashboard web temps rÃ©el
- [ ] Support chargements incrÃ©mentaux
- [ ] MÃ©triques Prometheus/Grafana

## ğŸ“š Fichiers gÃ©nÃ©rÃ©s

```
TRANSFORM/R2W/
â”œâ”€â”€ autoload_etl.py           # Script principal
â”œâ”€â”€ etl_checkpoint.json        # Checkpoint progression
â””â”€â”€ logs/
    â”œâ”€â”€ etl_auto_*.log         # Logs dÃ©taillÃ©s par exÃ©cution
    â””â”€â”€ snapshot_*.json        # Snapshots prÃ©-chargement
```

## âœ… Checklist prÃ©-exÃ©cution

- [ ] Docker PostgreSQL dÃ©marrÃ©
- [ ] Fichier .env prÃ©sent et correct
- [ ] Python 3.11+ installÃ©
- [ ] Librairies installÃ©es (requirements.txt)
- [ ] DonnÃ©es staging chargÃ©es (DATABASE/load_data.py exÃ©cutÃ©)
- [ ] SchÃ©ma DW initialisÃ© (DATAWAREHOUSE/init-warehouse.ps1 exÃ©cutÃ©)

---

**Auteur:** FarachaAz / SYSDECPRO  
**Version:** 1.0.0  
**Date:** 2025-11-18
